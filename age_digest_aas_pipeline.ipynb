{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.stats import pearsonr\n",
    "plt.rcParams['figure.dpi'] = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmtp_file_path = '/Users/eunicekoo/Downloads/fastas/combined_MTP_dict.p'\n",
    "\n",
    "with open(qmtp_file_path, 'rb') as f:\n",
    "    qMTP_dict = pickle.load(f)\n",
    "\n",
    "mtp_dict = {\n",
    "    key: {i: item for i, item in enumerate(value)} if isinstance(value, list) else {0: value}\n",
    "    for key, value in qMTP_dict.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_evidence_dict = {}\n",
    "\n",
    "diann_dir = '/Users/eunicekoo/Downloads/MTP FASTA DIANN 021025/'\n",
    "aa_subs_dir = '/Users/eunicekoo/Downloads/fastas/'\n",
    "\n",
    "# split up the evidence based on raw file\n",
    "file_paths = [\n",
    "    \"report_tp_1.tsv\",\n",
    "    \"report_tp_2.tsv\",\n",
    "    \"report_tp_3_5.tsv\",\n",
    "    \"report_tp_4.tsv\",\n",
    "    \"report_tp_6_2.tsv\"\n",
    "]\n",
    "\n",
    "report_file_1_9_lysc_trp = pd.concat([pd.read_csv(f, sep='\\t') for f in file_paths], ignore_index=True)\n",
    "report_file_1_9_lysc = pd.read_csv('report.tsv', sep='\\t', engine='python')\n",
    "\n",
    "report_file_1_9_lysc_trp = report_file_1_9_lysc_trp.loc[(report_file_1_9_lysc_trp['PEP'] <= 0.01), :]\n",
    "report_file_1_9_lysc = report_file_1_9_lysc.loc[(report_file_1_9_lysc['PEP'] <= 0.01), :]\n",
    "\n",
    "report_dfs_1_9_lysc_trp = {}\n",
    "report_dfs_1_9_lysc = {}\n",
    "\n",
    "raw_files_list_1_9_lysc_trp = list(set(report_file_1_9_lysc_trp['File.Name']))\n",
    "raw_files_list_1_9_lysc = list(set(report_file_1_9_lysc['File.Name']))\n",
    "\n",
    "for raw_file in raw_files_list_1_9_lysc_trp:\n",
    "    sub_df = report_file_1_9_lysc_trp[report_file_1_9_lysc_trp['File.Name'] == raw_file].reset_index(drop=True)\n",
    "    report_dfs_1_9_lysc_trp[raw_file] = sub_df\n",
    "\n",
    "for raw_file in raw_files_list_1_9_lysc:\n",
    "    sub_df = report_file_1_9_lysc[report_file_1_9_lysc['File.Name'] == raw_file].reset_index(drop=True)\n",
    "    report_dfs_1_9_lysc[raw_file] = sub_df\n",
    "    \n",
    "val_evidence_dict = {\n",
    "    'lysc+trp': report_dfs_1_9_lysc_trp,\n",
    "    'lysc': report_dfs_1_9_lysc\n",
    "    }\n",
    "\n",
    "pickle.dump(val_evidence_dict, open(aa_subs_dir+'validation_search_evidence_dict.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying mtps that are found in regular search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "512\n",
      "385\n",
      "634\n",
      "582\n",
      "242\n",
      "742\n",
      "385\n",
      "638\n",
      "700\n",
      "15\n",
      "500\n",
      "282\n",
      "598\n",
      "266\n",
      "606\n",
      "440\n",
      "431\n",
      "456\n",
      "321\n",
      "620\n",
      "91\n",
      "245\n",
      "162\n",
      "0\n",
      "310\n"
     ]
    }
   ],
   "source": [
    "# validaition 2 script\n",
    "\n",
    "# function for determining if sequence is identified in validation search\n",
    "def seq_in_val_search(idx, digest, raw_file):\n",
    "    \"\"\"\n",
    "    Input: index of mtp_dict[tmt_set], tmt_set (sample)\n",
    "    Output: if peptide is found, output = [index in mtp_dict, index in evidence file, index in mtp list at idx]\n",
    "    \"\"\"\n",
    "    val_ev_df = val_evidence_dict[digest][raw_file]\n",
    "    ev_seqs = list(val_ev_df['Stripped.Sequence'].values)\n",
    "    \n",
    "    mtp_list = mtp_dict['mistranslated sequence'][idx]\n",
    "    # some mtp entries have >1 putative AAS. If > identified in validation search, return as separate results\n",
    "    \n",
    "    for i, mtp in enumerate(mtp_list):\n",
    "        if mtp in ev_seqs:\n",
    "            # print(mtp_list)\n",
    "            # print([idx, [i for i, x in enumerate(ev_seqs) if x==mtp], i])\n",
    "            return([idx, [i for i, x in enumerate(ev_seqs) if x==mtp], i])\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "# apply validation search function to each mtp entry.\n",
    "print('Identifying mtps that are found in regular search')\n",
    "\n",
    "samples = [key for subdict in val_evidence_dict.values() if isinstance(subdict, dict) for key in subdict.keys()]\n",
    "val_hit_lists = {s:[] for s in samples}\n",
    "\n",
    "for digest_name, digest in val_evidence_dict.items():\n",
    "    for raw_file in digest:\n",
    "        for idx, value in tqdm(mtp_dict['Raw file'].items(), desc=f\"{digest_name} + {raw_file}\", leave=False):\n",
    "            result = seq_in_val_search(idx, digest_name, raw_file)\n",
    "            if result:\n",
    "                val_hit_lists[raw_file].append(result)\n",
    "\n",
    "\n",
    "# loop through lists of results, create new dict of validated MTPs with link to evidence file index\n",
    "val_mtp_dict = {}\n",
    "\n",
    "for s, val_list in val_hit_lists.items():\n",
    "    val_mtp_dict[s] = {k:{} for k in mtp_dict.keys()}\n",
    "    val_mtp_dict[s]['idx_val_evidence'] = {}\n",
    "\n",
    "    for i, val in enumerate(val_list):\n",
    "        mtp_idx = val[0]\n",
    "        seq_idx = val[2]\n",
    "        ev_idx = val[1]\n",
    "\n",
    "        for k in mtp_dict.keys():\n",
    "            if (isinstance(mtp_dict[k][mtp_idx], list)) and len(mtp_dict[k][mtp_idx])>0: # this is to make sure that we are extracting the correct AAS data and q-values for the mtp found out of list of mtps\n",
    "                val_mtp_dict[s][k][i] = mtp_dict[k][mtp_idx][seq_idx]\n",
    "            else:\n",
    "                val_mtp_dict[s][k][i] = mtp_dict[k][mtp_idx]\n",
    "        val_mtp_dict[s]['idx_val_evidence'][i] = ev_idx\n",
    "    print(len(val_mtp_dict[s]['idx_val_evidence']))\n",
    "\n",
    "pickle.dump(val_mtp_dict, open(aa_subs_dir+'Validated_MTP_dict.p', 'wb'))\n",
    "val_mtp_dict = pickle.load(open(aa_subs_dir+'Validated_MTP_dict.p', 'rb'))\n",
    "\n",
    "# function to determine the number of fragment ions supporting site of AAS\n",
    "def n_frags_over_MTP(frag_match, mtp, sub_idx, tmt_set):\n",
    "    \"\"\"\n",
    "    Input: fragment matches for peptide from msms.txt (MQ output file), peptide sequence, index of AAS on sequence, tmt_set\n",
    "    Output: number of fragment ions covering site of AAS\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for f, frag in enumerate(frag_match):\n",
    "        mtp_frag=0\n",
    "        if ('NH3' not in frag) and ('H2O' not in frag) and ('(' not in frag) and ('a' not in frag):\n",
    "            if 'b' in frag:\n",
    "                frag_start = 0\n",
    "                frag_end = int(frag[1:])\n",
    "                frag_seq = mtp[frag_start:frag_end]\n",
    "                if frag_end>sub_idx:\n",
    "                    mtp_frag = 1\n",
    "            elif 'y' in frag:\n",
    "                frag_start = -int(frag[1:])\n",
    "                frag_seq = mtp[frag_start:]\n",
    "                if len(mtp)+frag_start <= sub_idx:\n",
    "                    mtp_frag=1\n",
    "            count+=mtp_frag\n",
    "        \n",
    "    return(count)\n",
    "\n",
    "# apply function and annotate val_mtp_dict\n",
    "for digest_name, digest in val_evidence_dict.items():\n",
    "    for s in digest:\n",
    "        ev = val_evidence_dict[digest_name][s]\n",
    "        \n",
    "        val_mtp_dict[s]['fragment_evidence'] = {}\n",
    "        for k,v in val_mtp_dict[s]['aa subs'].items():\n",
    "            seq = val_mtp_dict[s]['mistranslated sequence'][k]\n",
    "            bp = val_mtp_dict[s]['DP Base Sequence'][k]\n",
    "            sub_idx = [i for i,x in enumerate(bp) if seq[i]!=x][0]\n",
    "            \n",
    "            ev_idx = val_mtp_dict[s]['idx_val_evidence'][k]\n",
    "            val_mtp_dict[s]['fragment_evidence'][k] = 0\n",
    "            for idx in ev_idx:\n",
    "                row = ev.iloc[idx,:]\n",
    "                fragment_row = row['Fragment.Info']\n",
    "    \n",
    "                if len(fragment_row)>0:\n",
    "                    frag_match = fragment_row.split(';')\n",
    "                    ion_types = [re.match(r'([yb]\\d+)', frag).group(1) for frag in frag_match if re.match(r'([yb]\\d+)', frag)]\n",
    "                    count_frags = n_frags_over_MTP(ion_types, seq, sub_idx, 'sample')\n",
    "                    \n",
    "                    if count_frags>val_mtp_dict[s]['fragment_evidence'][k]:\n",
    "                        val_mtp_dict[s]['fragment_evidence'][k] = count_frags\n",
    "\n",
    "\n",
    "# filter val_mtp_dict for those with b/y ion evidence\n",
    "val_ion_mtp_dict = {outer_key: {inner_key: {} for inner_key in inner_dict.keys()} for outer_key, inner_dict in val_evidence_dict.items() if isinstance(inner_dict, dict)}\n",
    "\n",
    "for digest_name, digest in val_evidence_dict.items():\n",
    "    for s in digest:\n",
    "        ion_idx = [i for i,x in val_mtp_dict[s]['fragment_evidence'].items() if x>1]\n",
    "        for k,v in val_mtp_dict[s].items():\n",
    "            val_ion_mtp_dict[digest_name][s][k] = {i:x for i,x in v.items() if i in ion_idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digest overlap calculation\n",
    "\n",
    "matched_report_lysc_trp = {}\n",
    "matched_report_lysc = {}\n",
    "\n",
    "global_seqs_lysc_trp = []\n",
    "for df in val_ion_mtp_dict['lysc+trp'].values():\n",
    "    global_seqs_lysc_trp.extend(list(df['mistranslated sequence'].values()))\n",
    "\n",
    "global_seqs_lysc = []\n",
    "for df in val_ion_mtp_dict['lysc'].values():\n",
    "    global_seqs_lysc.extend(list(df['mistranslated sequence'].values()))\n",
    "\n",
    "\n",
    "for digest_name, digest in val_ion_mtp_dict.items():\n",
    "    for raw_file, data_dict in digest.items():\n",
    "        \n",
    "        if digest_name == 'lysc+trp':\n",
    "            mask = {\n",
    "                key: any(str(s) == str(x) or str(s) in str(x) for x in global_seqs_lysc_trp)\n",
    "                for key, s in data_dict['mistranslated sequence'].items()\n",
    "            }\n",
    "\n",
    "        elif digest_name == 'lysc':\n",
    "            mask = {\n",
    "                key: any(str(s) == str(x)for x in global_seqs_lysc)\n",
    "                for key, s in data_dict['mistranslated sequence'].items()\n",
    "            }\n",
    "\n",
    "        for col in data_dict:\n",
    "            data_dict[col] = {key: value for key, value in data_dict[col].items() if mask.get(key, False)}\n",
    "\n",
    "pickle.dump(val_ion_mtp_dict, open(aa_subs_dir+'Ion_validated_MTP_dict.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r8/2581l79j2d309fq3kf12k3_h0000gn/T/ipykernel_96027/1338731329.py:100: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  prec_ratio = np.log2(mtp_prec_int / bp_prec_int)\n"
     ]
    }
   ],
   "source": [
    "# quant script\n",
    "\n",
    "mtp_dict = pickle.load(open(aa_subs_dir+'Ion_validated_MTP_dict.p', 'rb'))\n",
    "samples = list(mtp_dict.keys())\n",
    "val_evidence_dict = pickle.load(open(aa_subs_dir+'Validation_search_evidence_dict.p', 'rb'))\n",
    "\n",
    "unq_pairs = []\n",
    "unq_pair_dicts = []\n",
    "\n",
    "for digest_name, digest in mtp_dict.items():\n",
    "    for s, s_dict in digest.items():\n",
    "        for i, v in s_dict['aa subs'].items():\n",
    "            sub    = v\n",
    "            mtp    = s_dict['mistranslated sequence'][i]\n",
    "            bp     = s_dict['DP Base Sequence'][i]\n",
    "            ev_idx = s_dict['idx_val_evidence'][i]\n",
    "            pair = [mtp, bp]\n",
    "            if pair not in unq_pairs:\n",
    "                unq_pairs.append(pair)\n",
    "                unq_pair_dicts.append({\n",
    "                    'MTP': mtp, \n",
    "                    'BP': bp, \n",
    "                    'AAS': sub, \n",
    "                    'raw_files': {digest_name: [s]},\n",
    "                    'ev_idx_list': {digest_name: ev_idx},\n",
    "                    'raw_file_evidence': {digest_name: {s: [ev_idx]}},\n",
    "                    'digest_types': set([digest_name])\n",
    "                })\n",
    "            else:\n",
    "                curr_dict_idx = [j for j, x in enumerate(unq_pair_dicts) if (x['MTP'] == mtp and x['BP'] == bp)][0]\n",
    "                if digest_name in unq_pair_dicts[curr_dict_idx]['raw_files']:\n",
    "                    if s not in unq_pair_dicts[curr_dict_idx]['raw_files'][digest_name]:\n",
    "                        unq_pair_dicts[curr_dict_idx]['raw_files'][digest_name].append(s)\n",
    "                else:\n",
    "                    unq_pair_dicts[curr_dict_idx]['raw_files'][digest_name] = [s]\n",
    "                \n",
    "                if digest_name in unq_pair_dicts[curr_dict_idx]['ev_idx_list']:\n",
    "                    unq_pair_dicts[curr_dict_idx]['ev_idx_list'][digest_name].extend(ev_idx)\n",
    "                else:\n",
    "                    unq_pair_dicts[curr_dict_idx]['ev_idx_list'][digest_name] = ev_idx\n",
    "                \n",
    "                if digest_name in unq_pair_dicts[curr_dict_idx]['raw_file_evidence']:\n",
    "                    if s in unq_pair_dicts[curr_dict_idx]['raw_file_evidence'][digest_name]:\n",
    "                        unq_pair_dicts[curr_dict_idx]['raw_file_evidence'][digest_name][s].extend(ev_idx)\n",
    "                    else:\n",
    "                        unq_pair_dicts[curr_dict_idx]['raw_file_evidence'][digest_name][s] = ev_idx\n",
    "                else:\n",
    "                    unq_pair_dicts[curr_dict_idx]['raw_file_evidence'][digest_name] = {s: ev_idx}\n",
    "                \n",
    "                unq_pair_dicts[curr_dict_idx]['digest_types'].add(digest_name)\n",
    "\n",
    "    \n",
    "MTP_quant_dict = {}\n",
    "\n",
    "for i, pair in enumerate(unq_pair_dicts):\n",
    "    curr_dict = {\n",
    "        'MTP_seq': pair['MTP'], \n",
    "        'BP_seq': pair['BP'], \n",
    "        'sub_index': [idx for idx, x in enumerate(pair['MTP']) if pair['MTP'][idx] != pair['BP'][idx]], \n",
    "        'aa_sub': pair['AAS'],\n",
    "        'raw_files': pair['raw_files'], \n",
    "        'raw_file_evidence': pair['raw_file_evidence'],\n",
    "        'MTP_PrecInt': {},\n",
    "        'BP_PrecInt': {},\n",
    "        'Norm_MTP_PrecInt': {},\n",
    "        'Norm_BP_PrecInt': {},\n",
    "        'Prec_ratio': {},\n",
    "        'digest': list(pair['digest_types'])\n",
    "    }\n",
    "    MTP_quant_dict[i] = curr_dict\n",
    "    \n",
    "\n",
    "def median_normalize(sample_raw):\n",
    "    \"\"\"\n",
    "    Input: list of raw precursor intensities for tissue\n",
    "    Output: median-normalized list of precursor intensities for tissue\n",
    "    \"\"\"\n",
    "    sample_median = np.median(sample_raw)\n",
    "    sample_norm = [x / sample_median for x in sample_raw]\n",
    "    return sample_norm\n",
    "    \n",
    "\n",
    "def precursor_intensity_quant(k, tissue, digest_name):\n",
    "    \"\"\"\n",
    "    Input: k = index of MTP in MTP_quant_dict, tissue (raw file), digest_name.\n",
    "    Output: Returns precursor intensities for MTP and BP along with their normalized intensities and log2 ratio.\n",
    "            Precursor intensities represent the sum of all precursor quantities mapped to the peptide.\n",
    "    \"\"\"\n",
    "    bp = MTP_quant_dict[k]['BP_seq']\n",
    "    mtp = MTP_quant_dict[k]['MTP_seq']\n",
    "    ev_df = val_evidence_dict[digest_name][tissue]\n",
    "    bp_ev_df = ev_df.loc[ev_df['Stripped.Sequence'] == bp, :]\n",
    "    bp_prec_int = np.sum([x for x in bp_ev_df['Precursor.Quantity'].values if ~np.isnan(x)])\n",
    "    norm_bp_prec_int = np.sum([x for x in bp_ev_df['Precursor.Quantity'].values if ~np.isnan(x)])\n",
    "    \n",
    "    mtp_ev_df = ev_df.loc[ev_df['Stripped.Sequence'] == mtp, :]\n",
    "    mtp_prec_int = np.sum([x for x in mtp_ev_df['Precursor.Quantity'].values if ~np.isnan(x)])\n",
    "    norm_mtp_prec_int = np.sum([x for x in mtp_ev_df['Precursor.Quantity'].values if ~np.isnan(x)])\n",
    "    \n",
    "    prec_ratio = np.log2(mtp_prec_int / bp_prec_int)\n",
    "    return [mtp_prec_int, bp_prec_int, norm_mtp_prec_int, norm_bp_prec_int, prec_ratio]\n",
    "\n",
    "\n",
    "\"\"\"Quantification of precursor and reporter ions\"\"\"\n",
    "\n",
    "for digest_name, digest in val_evidence_dict.items():\n",
    "    for s in digest:\n",
    "        ev_df = val_evidence_dict[digest_name][s]\n",
    "        tissue = s\n",
    "        \n",
    "        for k, v in MTP_quant_dict.items():\n",
    "\n",
    "            if any(s in file_list for file_list in v['raw_files'].values()):\n",
    "                mtp = v['MTP_seq']\n",
    "                bp = v['BP_seq']\n",
    "                bp_ev = ev_df.loc[ev_df['Stripped.Sequence'] == bp, :]\n",
    "                mtp_ev = ev_df.loc[ev_df['Stripped.Sequence'] == mtp, :]\n",
    "        \n",
    "                mtp_prec_int, bp_prec_int, norm_mtp_prec_int, norm_bp_prec_int, prec_ratio = precursor_intensity_quant(k, tissue, digest_name)\n",
    "                v.setdefault('BP_PrecInt', {}).setdefault(digest_name, {})[tissue] = bp_prec_int\n",
    "                v.setdefault('MTP_PrecInt', {}).setdefault(digest_name, {})[tissue] = mtp_prec_int\n",
    "                v.setdefault('Norm_BP_PrecInt', {}).setdefault(digest_name, {})[tissue] = norm_bp_prec_int\n",
    "                v.setdefault('Norm_MTP_PrecInt', {}).setdefault(digest_name, {})[tissue] = norm_mtp_prec_int\n",
    "                v.setdefault('Prec_ratio', {}).setdefault(digest_name, {})[tissue] = prec_ratio\n",
    "\n",
    "pickle.dump(MTP_quant_dict, open(aa_subs_dir+'MTP_quant_dict.p', 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to age. also gets exported into spreadsheet\n",
    "run_to_age = {\n",
    "    1: 24, 2: 15, 3: 15, 4: 2, 5: 9, 6: 2, 7: 2, 8: 2, 9: 2, 10: 2, 11: 9, 12: 24, 13: 15, 14: 9, 15: 24, 16: 9, 17: 9, 18: 15, 19: 2, 20: 9, 21: 2, 22: 24, 23: 15, 24: 15, 25: 2\n",
    "}\n",
    "\n",
    "# get run number from the raw file\n",
    "def get_run_number(raw_file):\n",
    "    tp_match = re.search(r'TP_(\\d+)_', raw_file)\n",
    "    if tp_match:\n",
    "        return int(tp_match.group(1))\n",
    "    \n",
    "    run_match = re.search(r'BRAIN_RUN_(\\d+)_', raw_file)\n",
    "    if run_match:\n",
    "        return int(run_match.group(1))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making matrix with incomplete data\n",
    "\n",
    "all_raw_files = raw_files_list_1_9_lysc_trp + raw_files_list_1_9_lysc\n",
    "\n",
    "data = []\n",
    "\n",
    "for idx, entry in MTP_quant_dict.items():\n",
    "    row = {\n",
    "        'MTP_seq': entry['MTP_seq'],\n",
    "        'BP_seq': entry['BP_seq']\n",
    "    }\n",
    "    \n",
    "    for raw_file in all_raw_files:\n",
    "        prec_ratio = None\n",
    "        for digest in entry['raw_file_evidence'].keys():\n",
    "            if raw_file in entry['raw_file_evidence'][digest]:\n",
    "                if digest in entry['Prec_ratio'] and raw_file in entry['Prec_ratio'][digest]:\n",
    "                    prec_ratio = entry['Prec_ratio'][digest][raw_file]\n",
    "                    break\n",
    "        \n",
    "        row[raw_file] = prec_ratio\n",
    "    \n",
    "    data.append(row)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index(['MTP_seq', 'BP_seq'], inplace=True)\n",
    "df = df[all_raw_files]\n",
    "\n",
    "age_data = []\n",
    "for raw_file in all_raw_files:\n",
    "    filename = raw_file.split('/')[-1]\n",
    "    run_number = get_run_number(raw_file)\n",
    "    if run_number in run_to_age:\n",
    "        age_data.append({\n",
    "            'Raw File': filename,\n",
    "            'Full Path': raw_file,\n",
    "            'Age Group': run_to_age[run_number]\n",
    "        })\n",
    "\n",
    "age_df = pd.DataFrame(age_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r8/2581l79j2d309fq3kf12k3_h0000gn/T/ipykernel_96027/2716268421.py:28: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  r, p = pearsonr(raas[mask], age[mask])\n"
     ]
    }
   ],
   "source": [
    "# computing pearson correlation\n",
    "\n",
    "df_long = df.reset_index().melt(\n",
    "    id_vars=['MTP_seq', 'BP_seq'],\n",
    "    var_name='RawFile',\n",
    "    value_name='RAAS'\n",
    ")\n",
    "\n",
    "rawfile_to_age = dict(zip(age_df['Raw File'], age_df['Age Group']))\n",
    "df_long['Age'] = df_long['RawFile'].map(rawfile_to_age)\n",
    "\n",
    "df_long = df_long[\n",
    "    df_long['RAAS'].notna() &\n",
    "    df_long['Age'].notna() &\n",
    "    (df_long['RAAS'] != 0) &\n",
    "    (df_long['RAAS'] != np.inf) &\n",
    "    (df_long['RAAS'] != -np.inf)\n",
    "]\n",
    "\n",
    "results = []\n",
    "for (mtp, bp), group in df_long.groupby(['MTP_seq', 'BP_seq']):\n",
    "    if len(group) >= 2:\n",
    "        raas = pd.to_numeric(group['RAAS'], errors='coerce')\n",
    "        age = pd.to_numeric(group['Age'], errors='coerce')\n",
    "        mask = (~raas.isna()) & (~age.isna())\n",
    "        if mask.sum() >= 3:\n",
    "            unique_ages = age[mask].nunique()\n",
    "            r, p = pearsonr(raas[mask], age[mask])\n",
    "            results.append({\n",
    "                'MTP_seq': mtp,\n",
    "                'BP_seq': bp,\n",
    "                'R Value': r,\n",
    "                'P Value': p,\n",
    "                '# Raw Files': mask.sum(),\n",
    "                '# Age Groups': unique_ages \n",
    "            })\n",
    "\n",
    "cor_df = pd.DataFrame(results)\n",
    "\n",
    "# merging correlation df into spreadsheet\n",
    "\n",
    "df_reset = df.reset_index()\n",
    "df_merged = df_reset.merge(\n",
    "    cor_df[['MTP_seq', 'BP_seq', 'R Value', 'P Value', '# Raw Files', '# Age Groups']],\n",
    "    on=['MTP_seq', 'BP_seq'],\n",
    "    how='left'\n",
    ")\n",
    "df_merged.set_index(['MTP_seq', 'BP_seq'], inplace=True)\n",
    "\n",
    "with pd.ExcelWriter('raas_complete.xlsx') as writer:\n",
    "    df_merged.to_excel(writer, sheet_name='RAAS')\n",
    "    age_df.to_excel(writer, sheet_name='Age Groups', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of BP-MTP pairs present in all age groups: 73\n",
      "Number of peptides with valid RAAS values in all age groups: 73\n"
     ]
    }
   ],
   "source": [
    "# calculation code to get peptides present in all four age groups\n",
    "\n",
    "def get_run_number(raw_file):\n",
    "    tp_match = re.search(r'TP_(\\d+)_', raw_file)\n",
    "    if tp_match:\n",
    "        return int(tp_match.group(1))\n",
    "    \n",
    "    run_match = re.search(r'BRAIN_RUN_(\\d+)_', raw_file)\n",
    "    if run_match:\n",
    "        return int(run_match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "peptide_pairs_by_age = {2: set(), 9: set(), 15: set(), 24: set()}\n",
    "\n",
    "raas_by_peptide = {}\n",
    "\n",
    "for peptide in MTP_quant_dict.values():\n",
    "    mtp_seq = peptide['MTP_seq']\n",
    "    bp_seq = peptide['BP_seq']\n",
    "    pair = (bp_seq, mtp_seq)\n",
    "    \n",
    "    if pair not in raas_by_peptide:\n",
    "        raas_by_peptide[pair] = {2: [], 9: [], 15: [], 24: []}\n",
    "    \n",
    "    age_groups_with_both = set()\n",
    "    \n",
    "    for digest_name, digest_vals in peptide['Prec_ratio'].items():\n",
    "        for raw_file, value in digest_vals.items():\n",
    "            try:\n",
    "                val = float(value)\n",
    "                if not np.isfinite(val):\n",
    "                    continue\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            run = get_run_number(raw_file)\n",
    "            if run is not None:\n",
    "                age = run_to_age.get(run)\n",
    "                if age in peptide_pairs_by_age:\n",
    "                    age_groups_with_both.add(age)\n",
    "                    raas_by_peptide[pair][age].append(val)\n",
    "\n",
    "    for age in age_groups_with_both:\n",
    "        peptide_pairs_by_age[age].add(pair)\n",
    "\n",
    "common_pairs = set.intersection(*peptide_pairs_by_age.values())\n",
    "print(f\"Number of BP-MTP pairs present in all age groups: {len(common_pairs)}\")\n",
    "\n",
    "valid_peptides = {}\n",
    "for pair in common_pairs:\n",
    "    has_valid_values = True\n",
    "    median_raas_by_age = {}\n",
    "    n_points_by_age = {}\n",
    "    \n",
    "    for age in [2, 9, 15, 24]:\n",
    "        values = raas_by_peptide[pair][age]\n",
    "        if not values:\n",
    "            has_valid_values = False\n",
    "            break\n",
    "        median_raas_by_age[age] = np.median(values) \n",
    "        n_points_by_age[age] = len(values) \n",
    "    \n",
    "    if has_valid_values:\n",
    "        valid_peptides[pair] = {\n",
    "            'median_raas': median_raas_by_age,\n",
    "            'n_points': n_points_by_age\n",
    "        }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
